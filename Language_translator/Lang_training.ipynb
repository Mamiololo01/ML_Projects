{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow\n",
    "import sklearn\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#initialize all variables \n",
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_characters=set()\n",
    "target_characters=set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the dataset file\n",
    "\n",
    "We will traverse the dataset file and extract all the input and target texts. For this, we will be using the first 10,000 rows of our dataset for the training and testing part. It can be changed as per requirements. To separate input and target texts from the row we will use ‘\\t’ and to separate rows we will use ‘\\n’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset file\n",
    "with open('eng-french.txt','r',encoding='utf-8') as f:\n",
    "    rows=f.read().split('\\n')\n",
    "#read first 10,000 rows from dataset     \n",
    "for row in rows[:10000]:\n",
    "    #split input and target by '\\t'=tab\n",
    "    input_text,target_text = row.split('\\t')\n",
    "    #add '\\t' at start and '\\n' at end of text.\n",
    "    target_text='\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text.lower())\n",
    "    target_texts.append(target_text.lower())\n",
    "    #split character from text and add in respective sets\n",
    "    input_characters.update(list(input_text.lower()))\n",
    "    target_characters.update(list(target_text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same procedure and separate the text from rows and characters. Also, get the maximum length of encoder as well as decoder sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of encoder characters :  47\n",
      "number of decoder characters :  67\n",
      "maximum input length :  16\n",
      "maximum target length :  59\n"
     ]
    }
   ],
   "source": [
    "#sort input and target characters \n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "#get the total length of input and target characters\n",
    "num_en_chars = len(input_characters)\n",
    "num_dec_chars = len(target_characters)\n",
    "\n",
    "#get the maximum length of input and target text.\n",
    "max_input_length = max([len(i) for i in input_texts])\n",
    "max_target_length = max([len(i) for i in target_texts])\n",
    "\n",
    "print(\"number of encoder characters : \",num_en_chars)\n",
    "print(\"number of decoder characters : \",num_dec_chars)\n",
    "\n",
    "print(\"maximum input length : \",max_input_length)\n",
    "print(\"maximum target length : \",max_target_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models cannot work directly on the categorical data. For this, we require one hot encoding process. One-hot encoding deals with the data in binary format so we encode the categorical data in binary format.\n",
    "\n",
    "One-hot means that we can only make an index of data 1 (true) if it is present in the vector or else 0 (false). So every data has its unique representation in vector format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagofcharacters(input_texts,target_texts):\n",
    "  \n",
    "    # Initialize lists to store the data\n",
    "    en_in_data = []\n",
    "    dec_in_data = []\n",
    "    dec_tr_data = []\n",
    "\n",
    "    #padding variable with first character as 1 as rest all 0.\n",
    "    pad_en=[1]+[0]*(len(input_characters)-1)\n",
    "    pad_dec=[0]*(len(target_characters)) ; pad_dec[2]=1\n",
    "\n",
    "    #countvectorizer for one hot encoding as we want to tokenize character so\n",
    "    #analyzer is true and None the stopwords action.\n",
    "    cv=CountVectorizer(binary=True,tokenizer=lambda txt:\n",
    "    txt.split(),stop_words=None,analyzer='char')\n",
    "  \n",
    "    for i,(input_t,target_t) in enumerate(zip(input_texts,target_texts)):\n",
    "        #fit the input characters into the CountVectorizer function\n",
    "        cv_inp= cv.fit(input_characters)\n",
    "    \n",
    "        #transform the input text from the help of CountVectorizer fit.\n",
    "        #it character present than put 1 and 0 otherwise.\n",
    "        en_in_data.append(cv_inp.transform(list(input_t)).toarray().tolist())\n",
    "        cv_tar= cv.fit(target_characters)    \n",
    "        dec_in_data.append(cv_tar.transform(list(target_t)).toarray().tolist())\n",
    "\n",
    "        #decoder target will be one timestep ahead because it will not consider \n",
    "        #the first character i.e. '\\t'.\n",
    "        dec_tr_data.append(cv_tar.transform(list(target_t)[1:]).toarray().tolist())\n",
    "          #add padding variable if the length of the input or target text is smaller\n",
    "  #than their respective maximum input or target length. \n",
    "    if len(input_t) < max_input_length:\n",
    "      for _ in range(max_input_length-len(input_t)):\n",
    "        en_in_data[i].append(pad_en)\n",
    "    if len(target_t) < max_target_length:\n",
    "      for _ in range(max_target_length-len(target_t)):\n",
    "        dec_in_data[i].append(pad_dec)\n",
    "    if (len(target_t)-1) < max_target_length:\n",
    "      for _ in range(max_target_length-len(target_t)+1):\n",
    "        dec_tr_data[i].append(pad_dec)\n",
    "\n",
    "#convert list to numpy array with data type float32\n",
    "    en_in_data=np.array(en_in_data,dtype=\"float32\")\n",
    "    dec_in_data=np.array(dec_in_data,dtype=\"float32\")\n",
    "    dec_tr_data=np.array(dec_tr_data,dtype=\"float32\")\n",
    "    return en_in_data,dec_in_data,dec_tr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the training model\n",
    "\n",
    "In this language translation project, we will be using LSTM to train our machine learning model to translater language. LSTM (Long Short Term Memory) network: LSTM is a type of RNN (Recurrent Neural Network) that solves scenarios where RNN is failed.\n",
    "\n",
    "Long-Term Dependency: In RNN, networks have the data of previous output in memory for a short period of time because of this they are unaware about the actual context of the sentence over a long period of time. This raised the issue of long-term dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input object of total number of encoder characters\n",
    "en_inputs = Input(shape=(None, num_en_chars))\n",
    "\n",
    "#create LSTM with the hidden dimension of 256\n",
    "#return state=True as we don't want output sequence.\n",
    "encoder = LSTM(256, return_state=True)\n",
    "\n",
    "#discard encoder output and store hidden and cell state.\n",
    "en_outputs, state_h, state_c = encoder(en_inputs)\n",
    "en_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input object of total number of decoder characters\n",
    "dec_inputs = Input(shape=(None, num_dec_chars))\n",
    "\n",
    "#create LSTM with the hidden dimension of 256\n",
    "#return state and return sequences as we want output sequence.\n",
    "dec_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "\n",
    "#initialize the decoder model with the states on encoder.\n",
    "dec_outputs, _, _ = dec_lstm(dec_inputs, initial_state=en_states)\n",
    "\n",
    "#Output layer with shape of total number of decoder characters \n",
    "dec_dense = Dense(num_dec_chars, activation=\"softmax\")\n",
    "dec_outputs = dec_dense(dec_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "To train the model we will fit ‘(encoder input and decoder input)’ which will turn into (‘decoder target data’) using ‘Adam’ optimizer with a validation split of 0.2 and provide an epoch of 200 in a batch size of 64. Also, we will store all required variables in a binary or bytes stream like object format file using the ‘pickle’ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Model and store all variables \n",
    "model = Model([en_inputs, dec_inputs], dec_outputs)\n",
    "\n",
    "pickle.dump({'input_characters':input_characters,'target_characters':target_characters, 'max_input_length':max_input_length, 'max_target_length':max_target_length, 'num_en_chars':num_en_chars, 'num_dec_chars':num_dec_chars}, open(\"training_data.pkl\", \"wb\"))\n",
    "\n",
    "#load the data and train the model\n",
    "en_in_data,dec_in_data,dec_tr_data = bagofcharacters(input_texts,target_texts)\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [en_in_data, dec_in_data],\n",
    "    dec_tr_data,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">311,296</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,776</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,219</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m311,296\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m331,776\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)  │     \u001b[38;5;34m17,219\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,291</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660,291\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,291</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m660,291\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "#summary and model plot\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='Model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create Gui for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense\n",
    "\n",
    "BG_GRAY=\"#ABB2B9\"\n",
    "BG_COLOR=\"#000\"\n",
    "TEXT_COLOR=\"#FFF\"\n",
    "FONT=\"Melvetica 14\"\n",
    "FONT_BOLD=\"Melvetica 13 bold\"\n",
    "\n",
    "cv=CountVectorizer(binary=True,tokenizer=lambda txt: txt.split(),stop_words=None,analyzer='char') \n",
    "\n",
    "class LangTRans:\n",
    "    def __init__(self):\n",
    "        #initialize tkinter window and load the file\n",
    "        self.window=Tk()\n",
    "        self.main_window()\n",
    "        self.datafile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafile(self):\n",
    "    #get all datas from datafile and load the model.\n",
    "\n",
    "    datafile = pickle.load(open(\"training_data.pkl\",\"rb\"))\n",
    "    self.input_characters = datafile['input_characters']\n",
    "    self.target_characters = datafile['target_characters']\n",
    "\n",
    "    self.max_input_length = datafile['max_input_length']\n",
    "    self.max_target_length = datafile['max_target_length']\n",
    "    self.num_en_chars = datafile['num_en_chars']\n",
    "    self.num_dec_chars = datafile['num_dec_chars']\n",
    "\n",
    "    self.loadmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the main window for language translation. Also create scrollbar, text widget for the GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_window(self):\n",
    "    #add title to window and configure it\n",
    "    self.window.title(\"Language Translator\")\n",
    "    self.window.resizable(width=False,height=False)\n",
    "    self.window.configure(width=520,height=520,bg=BG_COLOR)\n",
    "\n",
    "    head_label=Label(self.window,bg=BG_COLOR, fg=TEXT_COLOR, text=\"Welcome to DataFlair\",font=FONT_BOLD, pady=10)\n",
    "    head_label.place(relwidth=1)\n",
    "\n",
    "    line = Label(self.window,width=450,bg=BG_COLOR)\n",
    "    line.place(relwidth=1,rely=0.07,relheight=0.012)\n",
    "\n",
    "    #create text widget where input and output will be displayed\n",
    "    self.text_widget=Text(self.window,width=20,height=2,bg=\"#fff\",fg=\"#000\", font=FONT,padx=5,pady=5)\n",
    "    self.text_widget.place(relheight=0.745,relwidth=1,rely=0.08)\n",
    "    self.text_widget.configure(cursor=\"arrow\",state=DISABLED)\n",
    "\n",
    "    #create scrollbar\n",
    "    scrollbar=Scrollbar(self.text_widget)\n",
    "    scrollbar.place(relheight=1,relx=0.974)\n",
    "    scrollbar.configure(command=self.text_widget.yview)\n",
    "\n",
    "    #create bottom label where text widget will placed\n",
    "    bottom_label=Label(self.window,bg=BG_GRAY,height=80)\n",
    "    bottom_label.place(relwidth=1,rely=0.825)\n",
    "\n",
    "    #this is for user to put english text\n",
    "    self.msg_entry=Entry(bottom_label,bg=\"#2C3E50\", fg=TEXT_COLOR,font=FONT)\n",
    "    self.msg_entry.place(relwidth=0.788,relheight=0.06,rely=0.008,relx=0.008)\n",
    "    self.msg_entry.focus()\n",
    "    self.msg_entry.bind(\"<Return>\",self.on_enter)\n",
    "\n",
    "    #send button which will call on_enter function to send the text\n",
    "    send_button=Button(bottom_label,text=\"Send\",font=FONT_BOLD, width=8,bg=\"#fff\",command=lambda: self.on_enter(None))        \n",
    "    send_button.place(relx=0.80,rely=0.008,relheight=0.06,relwidth=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (sampling) model and prediction\n",
    "\n",
    "Load the saved model and construct encoder and decoder. We will get the inputs from the saved model and LSTM to get the hidden and cell state of the encoder which is required to create the encoder model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmodel(self):\n",
    "    #Inference model\n",
    "    #load the model\n",
    "    model = models.load_model(\"s2s\")\n",
    "\n",
    "    #construct encoder model from the output of second layer\n",
    "    #discard the encoder output and store only states.\n",
    "    enc_outputs, state_h_enc, state_c_enc = model.layers[2].output \n",
    "\n",
    "    #add input object and state from the layer.\n",
    "    self.en_model = Model(model.input[0], [state_h_enc, state_c_enc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decoder, we will take the second input and create an input object for hidden as well for cell state of shape (256,) which is latent(hidden) dimension of layer. Also, we will run one step of the decoder with this initial state and a start of text character after that our output will be the next character of the text.\n",
    "\n",
    "We will use reverse lookup to get characters from the index of the ‘input_text’ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Input object for hidden and cell state for decoder\n",
    "#shape of layer with hidden or latent dimension\n",
    "dec_state_input_h = Input(shape=(256,), name=\"input_3\")\n",
    "dec_state_input_c = Input(shape=(256,), name=\"input_4\")\n",
    "dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
    "\n",
    "#add input from the encoder output and initialize with states.\n",
    "dec_lstm = model.layers[3]\n",
    "dec_outputs, state_h_dec, state_c_dec = dec_lstm(\n",
    "    model.input[1], initial_state=dec_states_inputs\n",
    ")\n",
    "\n",
    "dec_states = [state_h_dec, state_c_dec]\n",
    "dec_dense = model.layers[4]\n",
    "dec_outputs = dec_dense(dec_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(self,input_seq):\n",
    "    #create a dictionary with a key as index and value as characters.\n",
    "    reverse_target_char_index = dict(enumerate(self.target_characters))\n",
    "    #get the states from the user input sequence\n",
    "    states_value = self.en_model.predict(input_seq)\n",
    "\n",
    "    #fit target characters and \n",
    "    #initialize every first character to be 1 which is '\\t'.\n",
    "    #Generate empty target sequence of length 1.\n",
    "    co=cv.fit(self.target_characters) \n",
    "    target_seq=np.array([co.transform(list(\"\\t\")).toarray().tolist()],dtype=\"float32\")\n",
    "\n",
    "    #if the iteration reaches the end of text than it will be stop the it\n",
    "    stop_condition = False\n",
    "    #append every predicted character in decoded sentence\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        #get predicted output and discard hidden and cell state.\n",
    "        output_chars, h, c = self.dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "        #get the index and from the dictionary get the character.\n",
    "        char_index = np.argmax(output_chars[0, -1, :])\n",
    "        text_char = reverse_target_char_index[char_index]\n",
    "        decoded_sentence += text_char\n",
    "        # Exit condition: either hit max length\n",
    "    # or find a stop character.\n",
    "    if text_char == \"\\n\" or len(decoded_sentence) > self.max_target_length:\n",
    "        stop_condition = True\n",
    "    #update target sequence to the current character index.\n",
    "    target_seq = np.zeros((1, 1, self.num_dec_chars))\n",
    "    target_seq[0, 0, char_index] = 1.0\n",
    "    states_value = [h, c]\n",
    "#return the decoded sentence\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every index, put 1 to that index of our target array. So for the next iteration, our target sequence will be having a vector of the previous character. Iterate until our character is equal to the last character or max length of the target text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input (English) text from the user and pass it to a bag of characters for a one-hot encoding process. After that pass the encoded vector into ‘decode_sequence()’ for the decoded(french) text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagofcharacters(self, input_t):\n",
    "    cv = CountVectorizer(binary=True, tokenizer=lambda txt: txt.split(), stop_words=None, analyzer='char')\n",
    "    en_in_data = []\n",
    "    pad_en = [1] + [0] * (len(self.input_characters) - 1)\n",
    "\n",
    "    cv_inp = cv.fit(self.input_characters)\n",
    "    en_in_data.append(cv_inp.transform(list(input_t)).toarray().tolist())\n",
    "\n",
    "    if len(input_t) < self.max_input_length:\n",
    "        for _ in range(self.max_input_length - len(input_t)):\n",
    "            en_in_data[0].append(pad_en)\n",
    "\n",
    "    return np.array(en_in_data, dtype=\"float32\")\n",
    "\n",
    "def decoded_output(self, msg, sender):\n",
    "    self.text_widget.configure(state=NORMAL)\n",
    "    en_in_data = self.bagofcharacters(msg.lower() + \".\")\n",
    "    self.text_widget.insert(END, str(sender) + \" : \" + self.decode_sequence(en_in_data) + \"\\n\\n\")\n",
    "    self.text_widget.configure(state=DISABLED)\n",
    "    self.text_widget.see(END)\n",
    "\n",
    "def my_msg(self, msg, sender):\n",
    "    if not msg:\n",
    "        return\n",
    "    self.msg_entry.delete(0, END)\n",
    "    self.text_widget.configure(state=NORMAL)\n",
    "    self.text_widget.insert(END, str(sender) + \" : \" + str(msg) + \"\\n\")\n",
    "    self.text_widget.configure(state=DISABLED)\n",
    "\n",
    "# Run window\n",
    "def run(self):\n",
    "    self.window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
